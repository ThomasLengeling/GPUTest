

\chapter{Heterogeneous Computing} % Main chapter title

\label{Heterogeneous Computing} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 1. \emph{Heterogeneous Computing}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

Heterogeneous computing refers a system that combines several processor types to gain more performance. Typically using a single or multi-core computer processing units (CPUs) and a  graphics processing units (GPUs).
Typically GPUs are know for  3D graphics rendering and video games, but GPUs are becoming increasingly popular for accelerating computing applications and scientific research due to their low price, high performance and relatively low energy consumption per FLOPS (floating point operations per second) when compared with the CPUs. This chapter provides an overview of GPUs within the High Performance Computing (HPC) context, their advantages and disadvantages and how they can be integrated in to a scientific software and research.

%per watt better than cpu's


\section{Motivation}


The GPU has been essential part of personal computer since the early use. Over the course of 30 years the graphics architecture has evolve form drawing a simple 3d scene to be able to program each part of the GPU graphics pipeline. Their role became more important in the 90s with the first-person shooting video game DOOM by id Software. The demanding video game industry has brought year by year more realistic 3D graphics. Consequently new innovated hardware capabilities has been developed to increase the graphics pipeline and the render output. This lead to a more sophisticated programming environment with a massive parallel capabilities.

The fixed graphics pipeline (fixed functions on the GPU) was introduced in the early 90s, allowed various customization of the rendering process. However only allowed some modifications of the GPU output. Specific adjustment were extremely complicated did not allow custom algorithms. In 2001 NVIDIA and ATI (AMD) introduced the first programmability to the graphics pipeline. Which could control millions pixels and vertex output in a single frame. This was the beginning of GPU parallel capabilities.

At first the GPUs where only used for general-purpose computing like computer graphics, but in-till resent years the GPU has been used to accelerate scientific research, analytics, engineering, robotics and consumer applications.(GPGPU)\cite{physicsgpu}.

GPUs are attractive for certain type of scientific computation as they offer potential seed-up of multi-processors devices with the added advantages of being low cost, low maintenance, energy efficient, and relative simple to program. Many algorithms in applied physics are using GPUs to improve their performance over the CPU. Some examples are Euler Solver 16x seepd-up ( add Reference seed-up).

In any case, for a given simulation a compromise between speed and accuracy is always made. The current tendency of the CPU relies on increases the clock seeped and adding more cores per unit and be able to work and a parallel manner, because of the there are some limitations\cite{quantitative}

\begin{description}
  \item[Power Wall] \hfill \\
  The CPUs single core has not gone beyond the 4GHz barrier, a paradigm shift from a single core to a multi-core CPUs, also  the power use of CPUs is very high per Watt. The figure \ref{fig:gpu_cpu_s} shows the comparison of performance between the GPU and CPU.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.70\textwidth]{Figures/GPU_CPU_s.png}
		\rule{35em}{0.5pt}
	\caption[GPU and CPU]{GPU and CPU peak performance in gigaflops}
	\label{fig:gpu_cpu_s}
\end{figure}


  \item[Memory Wall] \hfill \\
  This refers to the growing disparity of speed between CPU  and the memory outside the CPU chip. Some applications have become memory bound, that is to say computing time is bounded by the transfer memory between the CPU and all the hardware devices connected to the CPU, commonly to the Peripheral Component Interconnect (PCI) chip. In conclusion the computing time is bounded by the memory not by the time calculations done on the CPU.

  \item[Parallelism Wall] \hfill \\
  This indicates a law that indicates the number of parallel processes. The number N parallel processes is never ideal and always depends on the problem.  The seed-up can be described by Amdahl's Law in terms of the fraction of parallelized work (f). \cite{quantitative}.

  $$speedup \leq \frac{N}{f + N(1-f)}$$



\end{description}



The current paradigm of using CPUs for computing growth is unsustainable. the largest supercomputers use around 10 megawatts (MWs) of power, this is enough to power a small town of 10,000 homes. If the current thread of power use continues, the next supercomputer would require 200 MWs of power, this would require a nuclear power reactor to run it! \cite{whatexascale}.

As said the GPU exceeds the CPU in calculations per second FLOPS with a low energy consumption. However the GPU is designed to launch small amounts of data in parallel with only several instructions, in other words the GPU swap, switch threads very fast, they are extremely lightweight. In a typical system, thousands of threads are waiting to work. While the CPU only run upto 24 threads on a hex-core processor. They can execute a single operation on comparatively large set of data with only one instruction. Although this can be extremely cost-wise operation on the GPU.

\section{GPUs as computing units}

A insight of the architecture of GPU can give a idea of  why it outperforms the CPU on various benchmarking.

The GPU, unlike its CPU cousin, has thousands for registers per SM (streaming multiprocessor), this are  arithmetic processing units. An SM can thought of like a multi-thread CPU core. On a typical CPU has two, four, six or eight cores. On a GPU as many as N SM core. We can see this in the figure \ref{fig:gpu_cpu}. For a particular calculation, all the stream
processors within a group execute exactly the same instruction on a particular data stream, then the data is sent to the upper level, the host (CPU). \cite{cook}

talk about what is a cuda core, historical comparison with new GPUs.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.42\textwidth]{Figures/GPU_CPU.png}
		\rule{35em}{0.5pt}
	\caption[Architecture of a GPU]{Architecture of a NVIDIA GeForce GTX 580}
	\label{fig:gpu_cpu}
\end{figure}

Being able to efficiently use a GPU for an application requires to expose the inherent data-parallelism Optimized for low-latency, serial computation. This can be seen in contrast with a CPU, which is optimized for sequential code performance, fast switching registers  and sophisticated control logic allowing to run single complex programs as fast as possible, which is not possible on the GPU. Memory management is very important for GPUs. this refers how to allocate memory space and transfer data between host (CPU) and device (GPU). While the CPU memory hierarchy is almost non-existent, on the GPU inherent data is important. In figure \ref{fig:arch} different levels of memory can be observer between the host and the device, which differs form the CPU \cite{hwu}.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.68\textwidth]{Figures/arch.png}
		\rule{35em}{0.5pt}
	\caption[Host and Device]{Memory transfer between the host and device}
	\label{fig:arch}
\end{figure}



On the GPU precision and optimization are very important but there is a penalty for choosing performance or precession. All the GPUs are optimized for single precision floating operations, 24 bit size, Also provides double precision point, size of  53 bits. This is using the standard notation IEEE 754. Normally the GPU uses single precession(SP) by default, if choosed double precision (DP), normally there is a penalty of  2x - 4x seed-up. \cite{precision}
Libraries such as CUBLAS and CUFFT provides useful information how NVIDIA handles floating point operations under the hood.


\section{Programming on GPUs}

There exist, among many, two main computing platforms, NVIDIA's Compute Unified Device Architecture (CUDA), and Khronos's Open Computing Language (OpenCL). NVIDIA's CUDA provides the necessary tools, frameworks and library to programs parallel computing, but for there GPUs. While OpenCL is a open standard framework meaning that is possible to do parallel computing on other GPUs, like on AMD cards. Programmers can easily port their code to others graphics cars.  However CUDA has more robust debugging and profiling for GPGPU computing. This two frameworks are developed to be close to the hardware layer, using C programming language. CUDA provides both a low level API and a higher level API. Those who are familiar to OpenCL and CUDa, can easily modify their code to work on either platform.\cite{hwu}

The CUDA programming model views the GPU as an accelerator processor which calls parallel programs  throughout all the SMI. This programs are only called on the device and are called kernels, which launch a large amounts of threads to execute CUDA code. The basic idea of programming on a GPU is simple. We can observer this in the figure \ref{fig:cycle}

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.3\textwidth]{Figures/cycle.png}
		\rule{35em}{0.5pt}
	\caption[Programming Cycle]{Programming Cycle between the CPU and GPU}
	\label{fig:cycle}
\end{figure}


\begin{itemize}
\item Create memory(data) for the host (CPU) and devices (GPUs)
\item Send the data host memory to the highly parallel device.
\item Do something with data on the device, e.g. matrix multiplication,calculation, parallel algorithm.
\item Return the data from the device to the host.
\end{itemize}

The structure of CUDA reflects the coexistence of CPU and GPUs. The CUDA code is a mixture of both host code and device code. The CUDA C compiler is called NVCC. The host code is the standard low level ANSI C language. The device code is marked is CUDA keywords for identifying data-parallel functions and has a extension file .cu.

When a kernel is launched, executed by a large amount of threads, where they are organized as a one, two or three dimensional grid of thread blocks. A thread is the simplest executing process. It consists of the code of the program, the particular point where the code is being executed. \cite{hwu}. Many threads form a block, and many blocks form a grid. CUDA handles the execution of th threads, which take up-to very few clock cycles in comparison to CPU threads. The threads per block can be observer in figure \ref{fig:grid}. All the threads in a kernel can access the global memory, figure \ref{fig:arch}.

Each of the threads can be access by implicit variable that identifies its position within the thread block and its grid. In a case of 1-D block. \cite{example}

$$blockIdx.x \times blockDim.x + threadId.x$$

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.6\textwidth]{Figures/grid.png}
		\rule{35em}{0.5pt}
	\caption[Part of the CUDA's 2D grid]{Part of a 2D CUDA's thread grid, divided in blocks, each block with it’s own respective threads.}
	\label{fig:grid}
\end{figure}

In CUDA. host and device have separate memory spaces. This can bee seen on the host and device with the DRAM(Dynamic random-acess memory) data. For example a NVIDIA GTX 660m comes with 2GB of memory, which is the global memory for the device. As told the host and device allocates data. The programmer needs to send data from the host memory to the device's global memory. We can see this in the figure  \ref{memorySpace:arch}.  Once the memory is transfer back to the host, is completely necessary to free the memory from the device and host. This is typically done with free or delete on C/C++. The CUDA's Application Programming Interface (API) functions performs this activities on behalf of the programmer.   \cite{hwu}

\begin{figure}[htbp]
	\centering
		\includegraphics[width=0.6\textwidth]{Figures/memorySpace.png}
		\rule{35em}{0.5pt}
	\caption[Memory Space GPU and CPU]{Separate memory spaces for the CPU and GPU}
	\label{fig:memorySpace}
\end{figure}

\section{Vector Addition Example}

Include a Simple Vector addition example with the GPU and CPU. \\

This chapter provided a quick overview of heterogeneous programming in a modern context. CUDA  enhance the C language with parallel computing support. Which is possible to launch  enormous amounts of parallel threads, oppose of few threads on the CPU. The number of GPU cores will continue to increase in proportion to increase in available transistors as silicon process improve. In addition, GPUs will continue to go through vigorous architectural evolution. Despite their demonstration high performance on data-parallel applications. \cite{hwu}








