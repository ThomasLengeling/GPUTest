% Chapter Template

\chapter{Conclusions and future work} % Main chapter title

\label{Conclusions and future work} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 6. \emph{Conclusions and future work}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

GPUs definitely have a place in the world of computational physics and other similar applications, their use allows to do the same work with less energy and more science with less resources. They make HPC computing clusters affordable for small research groups. The true limit test of this new technology will be if it is actually used to advance new science. In the field of computational physics studies that do push the barrier of what is computationally feasible, from speedups of 1.5x to 20x using GPUs\cite{applications}.

Acceptance has been slow due to many factors, GPUs are sometimes seen as a fad or a niche, the specialized skill set and effort required for GPU programming along with the risk of spending money to setup a GPU cluster, does raise a concern for productivity and viability of this technology. Adopting this technology requires abandoning legacy codes and smart optimizations that have been developed over the years. A wrong choice may result in wasted time and effort.
What is certain is at the moment, is the overall direction of the industry towards higher parallelism, as single threaded performance has reached a local limit, all types of processors are seeking more performance out of parallelism. This means that a large portion of the work needed to parallelize a code for a certain parallel architecture will most probably be applicable to another parallel architecture as well. From the literature and my experiences, one can observe that in order to achieve good results in programming with GPUs it is necessary to take a Heterogeneous approach to coding. That is adopting multi-threaded CPUs and concurrent GPU type algorithms.

Spintronics, in particular involves designing new magnetic materials for spin-devices and modeling and understanding of spin-transport at molecular and atomic scale. Manipulating magnetic domain walls to store and transfer information is envisioned to enable high-density, low-power, non-volatile, and non-mechanical memory. Promising for future systems for example the racetrack memory by Parkin at IBM, where DWs can be moved by applied magnetic fields and/or by currents via the spin transfer torque effects such as the simulation proposed by this research. However, most of the technologies and experiments  are still in develop. Furthermore, there are several obstacles to be overcome to enable these technologies.

Using computer simulation is possible to predict the outcome of the theoretical approach. In this case reproduce the effects of spin diffusion by numerically implementing the Zhang-Li model into micormagnetics, we apply a current to a regime of DWs in a NiFe soft nanostrips. Furthermore, providing the theoretical experiments with high precision on relative inexpensive computers. By using the highly parallel capabilities of the GPU it was possible to dramatically reduce the computation time of the simulation from around 400s on the non-threaded CPU version to 41s on a GPU. Therefore is now possible to execute 10 times more simulations on the same time frame.

Through the optimization we achieved a maximum speedup of 8.0x. The result did not occur on the newest device, the K20m. But on the mid-range GPU, the GeForce GTX 580, which has more clock cycles (GHz) than the others cards. The newest device, the K20m is 10 times more expensive than the 580 card. The Tesla cards are mainly designed for server used, multiple users, while the GeForce for high performance graphics, high workload on a single user. The  optimization approach was focused on giving more workload on the GPUs, more performance per SM and increasing the work of threads per block. Lastly, the GTX 580 is not the newest GeForce card available in the market, the new GeForce 980 is expected to have a 40$\%$ increase in performance over the 500 GTX series. 

The simulations were performed on a relative small data set. Moreover, is possible to increase the data set, in other words, a bigger magnetization data. Which overall will reduce the execution time by a factor of 8.0, increasing the number of simulations in the same time frame. Future test are likely to be performed on a newer GPU architectures, such as the Maxwell. For example, on the new GeForce 980 or on the Tesla K80.

The current thread is to push the hardware capabilities and performance along with Mooers' Law, despite these issues there are some trends in the hardware industry that will make working with GPU easier and more widespread within a HPC context:

\begin{description}
  \item[3D Memory] \hfill \\
 Stacks DRAM chips into dense modules with wide interfaces, and brings them inside the same package as the GPU. This lets GPUs get data from memory more quickly – boosting throughput and efficiency – allowing us to build more compact GPUs that put more power into smaller devices. The result: several times greater bandwidth, more than twice the memory capacity and quadrupled energy efficiency.
  
  \item[NVLink] \hfill \\
 Today’s computers are constrained by the speed at which data can move between the CPU and GPU. NVLink puts a fatter pipe between the CPU and GPU, allowing data to flow at more than 80GB per second, compared to the 16GB per second available now.
 
 \item[Pascal Module] \hfill \\ 
  NVIDIA has designed a module to house Pascal GPUs with NVLink. At one-third the size of the standard boards used today, they’ll put the power of GPUs into more compact form factors than ever before.
  
   \item[Mobile and embedded Devices] \hfill \\ 
   With the new Tegra K1 is possible to do supercomputing on the level of mobil devices, achieving upto 1 TFlops of performance. Embedded systems with CUDA capabilities is possible to integrate high performance algorithms to such small platforms. 
   \item[Cloud Computing] \hfill \\ 
   NVIDIA is pushing the limits of bring computer graphics to the cloud, the idea is for everybody have access to high quality computer graphics.
 
  \end{description}
  
\vspace{2.5em}


Using heterogenous computing is possible to dramatically decrease computational time on CPU applications that are not feasible with the current CPU paradigm. Leaving room for new types computational simulations in a reasonable time frame.  To conclude, I offer my personal perspective on GPU computing. I think the importance of using accelerator hardware is an economic and environmental issue. The environmental aspect of doing computing is often overlooked, but an ever increasing important one. As heavy computer users we will have to take responsibility for our electricity use. The benefit of less energy use is clear with more computational power. 
